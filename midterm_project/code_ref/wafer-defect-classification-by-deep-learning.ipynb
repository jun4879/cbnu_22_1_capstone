{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, Input, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datapath = join('data', 'wafer')\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"../input/wm811k-wafer-map/LSWMD.pkl\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['waferIndex'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dim(x):\n",
    "    dim0=np.size(x,axis=0)\n",
    "    dim1=np.size(x,axis=1)\n",
    "    return dim0,dim1\n",
    "df['waferMapDim']=df.waferMap.apply(find_dim)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['failureNum']=df.failureType\n",
    "df['trainTestNum']=df.trianTestLabel\n",
    "mapping_type={'Center':0,'Donut':1,'Edge-Loc':2,'Edge-Ring':3,'Loc':4,'Random':5,'Scratch':6,'Near-full':7,'none':8}\n",
    "mapping_traintest={'Training':0,'Test':1}\n",
    "df=df.replace({'failureNum':mapping_type, 'trainTestNum':mapping_traintest})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_wafers = df.shape[0]\n",
    "tol_wafers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_withlabel = df[(df['failureNum']>=0) & (df['failureNum']<=8)]\n",
    "df_withlabel =df_withlabel.reset_index()\n",
    "df_withpattern = df[(df['failureNum']>=0) & (df['failureNum']<=7)]\n",
    "df_withpattern = df_withpattern.reset_index()\n",
    "df_nonpattern = df[(df['failureNum']==8)]\n",
    "df_withlabel.shape[0], df_withpattern.shape[0], df_nonpattern.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import gridspec\n",
    "fig = plt.figure(figsize=(20, 4.5)) \n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[1, 2.5]) \n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "\n",
    "no_wafers=[tol_wafers-df_withlabel.shape[0], df_withpattern.shape[0], df_nonpattern.shape[0]]\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "explode = (0.1, 0, 0)  # explode 1st slice\n",
    "labels = ['no-label','label and pattern','label and non-pattern']\n",
    "ax1.pie(no_wafers, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "uni_pattern=np.unique(df_withpattern.failureNum, return_counts=True)\n",
    "labels2 = ['','Center','Donut','Edge-Loc','Edge-Ring','Loc','Random','Scratch','Near-full']\n",
    "ax2.bar(uni_pattern[0],uni_pattern[1]/df_withpattern.shape[0], color='green', align='center', alpha=0.9)\n",
    "ax2.set_title(\"failure type frequency\")\n",
    "ax2.set_ylabel(\"% of pattern wafers\")\n",
    "ax2.set_xticklabels(labels2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.loc[df['waferMapDim'] == (26, 26)]\n",
    "sub_wafer = sub_df['waferMap'].values\n",
    "\n",
    "sw = np.ones((1, 26, 26))\n",
    "label = list()\n",
    "\n",
    "for i in range(len(sub_df)):\n",
    "    # skip null label\n",
    "    if len(sub_df.iloc[i,:]['failureType']) == 0:\n",
    "        continue\n",
    "    sw = np.concatenate((sw, sub_df.iloc[i,:]['waferMap'].reshape(1, 26, 26)))\n",
    "    label.append(sub_df.iloc[i,:]['failureType'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sw[1:]\n",
    "y = np.array(label).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x shape : {}, y shape : {}'.format(x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 1st data\n",
    "plt.imshow(x[2040])\n",
    "plt.show()\n",
    "\n",
    "# check faulty case\n",
    "print('Faulty case : {} '.format(y[2040]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((-1, 26, 26, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_case = np.unique(y)\n",
    "print('Faulty case list : {}'.format(faulty_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in faulty_case :\n",
    "    print('{} : {}'.format(f, len(y[y==f])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.zeros((len(x), 26, 26, 3))\n",
    "\n",
    "for w in range(len(x)):\n",
    "    for i in range(26):\n",
    "        for j in range(26):\n",
    "            new_x[w, i, j, int(x[w, i, j])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "input_shape = (26, 26, 3)\n",
    "input_tensor = Input(input_shape)\n",
    "encode = layers.Conv2D(64, (3,3), padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "latent_vector = layers.MaxPool2D()(encode)\n",
    "\n",
    "# Decoder\n",
    "decode_layer_1 = layers.Conv2DTranspose(64, (3,3), padding='same', activation='relu')\n",
    "decode_layer_2 = layers.UpSampling2D()\n",
    "output_tensor = layers.Conv2DTranspose(3, (3,3), padding='same', activation='sigmoid')\n",
    "\n",
    "# connect decoder layers\n",
    "decode = decode_layer_1(latent_vector)\n",
    "decode = decode_layer_2(decode)\n",
    "\n",
    "ae = models.Model(input_tensor, output_tensor(decode))\n",
    "ae.compile(optimizer = 'Adam',\n",
    "              loss = 'mse',\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=30\n",
    "batch_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start train\n",
    "ae.fit(new_x, new_x,\n",
    "       batch_size=batch_size,\n",
    "       epochs=epoch,\n",
    "       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models.Model(input_tensor, latent_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input((13, 13, 64))\n",
    "decode = decode_layer_1(decoder_input)\n",
    "decode = decode_layer_2(decode)\n",
    "\n",
    "decoder = models.Model(decoder_input, output_tensor(decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode original faulty wafer\n",
    "encoded_x = encoder.predict(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to encoded latent faulty wafers vector.\n",
    "noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 13, 13, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check original faulty wafer data\n",
    "plt.imshow(np.argmax(new_x[3], axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check new noised faulty wafer data\n",
    "noised_gen_x = np.argmax(decoder.predict(noised_encoded_x), axis=3)\n",
    "plt.imshow(noised_gen_x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment function define\n",
    "def gen_data(wafer, label):\n",
    "    # Encode input wafer\n",
    "    encoded_x = encoder.predict(wafer)\n",
    "    \n",
    "    # dummy array for collecting noised wafer\n",
    "    gen_x = np.zeros((1, 26, 26, 3))\n",
    "    \n",
    "    # Make wafer until total # of wafer to 2000\n",
    "    for i in range((2000//len(wafer)) + 1):\n",
    "        noised_encoded_x = encoded_x + np.random.normal(loc=0, scale=0.1, size = (len(encoded_x), 13, 13, 64)) \n",
    "        noised_gen_x = decoder.predict(noised_encoded_x)\n",
    "        gen_x = np.concatenate((gen_x, noised_gen_x), axis=0)\n",
    "    # also make label vector with same length\n",
    "    gen_y = np.full((len(gen_x), 1), label)\n",
    "    \n",
    "    # return date without 1st dummy data.\n",
    "    return gen_x[1:], gen_y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation for all faulty case.\n",
    "for f in faulty_case : \n",
    "    # skip none case\n",
    "    if f == 'none' : \n",
    "        continue\n",
    "    \n",
    "    gen_x, gen_y = gen_data(new_x[np.where(y==f)[0]], f)\n",
    "    new_x = np.concatenate((new_x, gen_x), axis=0)\n",
    "    y = np.concatenate((y, gen_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After Generate new_x shape : {}, new_y shape : {}'.format(new_x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in faulty_case :\n",
    "    print('{} : {}'.format(f, len(y[y==f])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_idx = np.where(y=='none')[0][np.random.choice(len(np.where(y=='none')[0]), size=11000, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.delete(new_x, none_idx, axis=0)\n",
    "new_y = np.delete(y, none_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After Delete \"none\" class new_x shape : {}, new_y shape : {}'.format(new_x.shape, new_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in faulty_case :\n",
    "    print('{} : {}'.format(f, len(new_y[new_y==f])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in enumerate(faulty_case):\n",
    "    new_y[new_y==l] = i\n",
    "    \n",
    "# one-hot-encoding\n",
    "new_y = to_categorical(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X=new_x[0:19000]\n",
    "new_Y=new_y[0:19000]\n",
    "test_x=new_x[19001:19706]\n",
    "test_y=new_y[19001:19706]\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(new_X, new_Y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train x : {}, y : {}'.format(x_train.shape, y_train.shape))\n",
    "print('Test x: {}, y : {}'.format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_shape = (26, 26, 3)\n",
    "    input_tensor = Input(input_shape)\n",
    "\n",
    "    conv_1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(input_tensor)\n",
    "    conv_2 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(conv_1)\n",
    "    conv_3 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(conv_2)\n",
    "\n",
    "    flat = layers.Flatten()(conv_3)\n",
    "\n",
    "    dense_1 = layers.Dense(512, activation='relu')(flat)\n",
    "    dense_2 = layers.Dense(128, activation='relu')(dense_1)\n",
    "    output_tensor = layers.Dense(9, activation='softmax')(dense_2)\n",
    "\n",
    "    model = models.Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer='Adam',\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=1024, verbose=2) \n",
    "# 3-Fold Crossvalidation\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=2019) \n",
    "results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "# Check 3-fold model's mean accuracy\n",
    "print('Simple CNN Cross validation score : {:.4f}'.format(np.mean(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "         validation_data=[x_test, y_test],\n",
    "         epochs=epoch,\n",
    "         batch_size=batch_size,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(x_test, y_test)\n",
    "#print('Test Loss:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "print('Testing Accuracy:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy plot \n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# loss plot\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
